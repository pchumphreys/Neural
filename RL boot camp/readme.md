My version of the code from the RL bootcamp (https://sites.google.com/view/deep-rl-bootcamp/lectures)

As an exercise, I extended the A2C code to include PPO. Seems to provide a small amount of improvement, although I haven't made any effort to optimise parameters.

